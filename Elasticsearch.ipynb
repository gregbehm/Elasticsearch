{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For guidance, see [Elastic Stack and Product Documentation](https://www.elastic.co/guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Elasticsearch Client docs at http://elasticsearch-py.readthedocs.io\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pathlib\n",
    "import time\n",
    "# twittertools is my local twittertools.py module\n",
    "import twittertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Elasticsearch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default connection to localhost:9200\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print current indices for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow open twitter O8Xp5vwfTcqAR4ex3LNsUQ 5 1 12908 0  8.5mb  8.5mb\n",
      "yellow open .kibana Yuy-vovlQyeUPVim2PcdFw 1 1     2 0 10.9kb 10.9kb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(es.cat.indices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweets from a few Twitter user timelines; index them in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration only, delete any existing /twitter index\n",
    "result = es.indices.delete(index='twitter', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Authenticated TwitterTools object\n",
    "filepath = pathlib.Path.home().joinpath('.twitter', 'credentials.json')\n",
    "twt = twittertools.TwitterTools(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3248 tweets retrieved from @pourmecoffee's timeline; 3248 indexed\n",
      "3239 tweets retrieved from @washingtonpost's timeline; 3239 indexed\n",
      "3204 tweets retrieved from @brainpicker's timeline; 3204 indexed\n",
      "3233 tweets retrieved from @wilw's timeline; 3233 indexed\n",
      "Total tweets indexed: 12924\n"
     ]
    }
   ],
   "source": [
    "all_indexed = 0\n",
    "total_tweets = 0\n",
    "screen_names = ['pourmecoffee', 'washingtonpost', 'brainpicker', 'wilw']\n",
    "for screen_name in screen_names: \n",
    "    tweets = twt.get_user_timeline(screen_name)\n",
    "    total_tweets += len(tweets)\n",
    "    print(f\"{len(tweets)} tweets retrieved from @{screen_name}'s timeline;\", end=' ')\n",
    "    total_indexed = 0\n",
    "    for tweet in tweets:\n",
    "        doc = twittertools.unpack_tweet(tweet)\n",
    "        result = es.index(index='twitter', doc_type='tweet', body=doc)\n",
    "        if result['_shards']['successful']:\n",
    "            total_indexed += 1\n",
    "    print(f'{total_indexed} indexed', flush=True)\n",
    "    all_indexed += total_indexed\n",
    "print('Total tweets indexed:', all_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm number of tweets indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzz...zzz...\n",
      "Found 12924 indexed tweets\n"
     ]
    }
   ],
   "source": [
    "# There seems to be latency between indexing and getting\n",
    "# correct search results. Introduce a short wait...\n",
    "sleep_time = 0.50\n",
    "search = Search(using=es, index='twitter', doc_type='tweet')\n",
    "while True:\n",
    "    if search.count() == all_indexed:\n",
    "        break\n",
    "    print('zzz...', end='')\n",
    "    time.sleep(sleep_time)\n",
    "print(f'\\nFound {all_indexed} indexed tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform simple match query on tweet texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 35 matches\n",
      "Top ten by relevance score:\n",
      "- pourmecoffee 2017-06-05T22:31:52Z @NASA Like my tweets.\n",
      "- pourmecoffee 2017-06-29T17:40:25Z @NASA @CassiniSaturn pierogi mmm\n",
      "- pourmecoffee 2017-07-12T18:24:04Z @NASA Finally some non-Manhatten-sized icebergs.\n",
      "- washingtonpost 2017-11-29T08:05:43Z A NASA astronaut films his spacewalk — and a breathtaking view of Earth https://t.co/ZaCEVRbTME\n",
      "- pourmecoffee 2017-08-18T11:51:27Z @NASA @NASA_TDRS You're firing on Earth do you take me for a fool?\n",
      "- washingtonpost 2017-11-15T23:01:18Z These are the melting glaciers that might someday drown your city, according to NASA https://t.co/hTuR9CobAf\n",
      "- washingtonpost 2017-11-28T18:58:00Z A NASA astronaut films his spacewalk — and a breathtaking view of Earth https://t.co/3WrPgggQVF\n",
      "- pourmecoffee 2017-09-10T01:43:52Z NASA engineers these releases every ten years to keep the people docile. I've said too much already.\n",
      "- pourmecoffee 2017-09-07T22:54:20Z Rare shot from NASA of Carl Sagan just minutes after he landed on Earth. https://t.co/XlXNWKubTn\n",
      "- washingtonpost 2017-11-27T14:16:30Z NASA launched this record into space in 1977. Now, you can own your own copy. https://t.co/10C1dNvy6l\n"
     ]
    }
   ],
   "source": [
    "results = search.query(\"match\", text=\"NASA\").execute()\n",
    "print(f'Got {results[\"hits\"][\"total\"]} matches')\n",
    "print('Top ten by relevance score:')\n",
    "for hit in results['hits']['hits']:\n",
    "    tweet = hit['_source']\n",
    "    print('-', tweet['screen_name'], tweet['created'], tweet['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
