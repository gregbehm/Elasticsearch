{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For guidance, see [Elastic Stack and Product Documentation](https://www.elastic.co/guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pathlib\n",
    "import time\n",
    "# twittertools is my local twittertools.py module\n",
    "import twittertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Elasticsearch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default connection to localhost:9200\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print current indices for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow open twitter FyCk4wKaTz-V_gRaHReVMw 5 1 12908 0  8.6mb  8.6mb\n",
      "yellow open blogs   rMlnHDk0RHGKIoAiOMqxdw 3 2     0 0   792b   792b\n",
      "yellow open .kibana Yuy-vovlQyeUPVim2PcdFw 1 1     2 0 10.9kb 10.9kb\n",
      "yellow open website HaP0rQARQlClPc2McT5dsg 5 1     1 0  5.8kb  5.8kb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(es.cat.indices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweets from a few Twitter user timelines; index them in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration only, delete any existing /twitter index\n",
    "result = es.indices.delete(index='twitter', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Authenticated TwitterTools object\n",
    "filepath = pathlib.Path.home().joinpath('.twitter', 'credentials.json')\n",
    "twt = twittertools.TwitterTools(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3247 tweets retrieved from @pourmecoffee's timeline; 3247 indexed\n",
      "3228 tweets retrieved from @washingtonpost's timeline; 3228 indexed\n",
      "3202 tweets retrieved from @brainpicker's timeline; 3202 indexed\n",
      "3231 tweets retrieved from @wilw's timeline; 3231 indexed\n",
      "Total tweets indexed: 12908\n"
     ]
    }
   ],
   "source": [
    "all_indexed = 0\n",
    "total_tweets = 0\n",
    "screen_names = ['pourmecoffee', 'washingtonpost', 'brainpicker', 'wilw']\n",
    "for screen_name in screen_names: \n",
    "    tweets = twt.get_user_timeline(screen_name)\n",
    "    total_tweets += len(tweets)\n",
    "    print(f\"{len(tweets)} tweets retrieved from @{screen_name}'s timeline;\", end=' ')\n",
    "    total_indexed = 0\n",
    "    for tweet in tweets:\n",
    "        doc = twittertools.unpack_tweet(tweet)\n",
    "        result = es.index(index='twitter', doc_type='tweet', body=doc)\n",
    "        if result['_shards']['successful']:\n",
    "            total_indexed += 1\n",
    "    print(f'{total_indexed} indexed', flush=True)\n",
    "    all_indexed += total_indexed\n",
    "print('Total tweets indexed:', all_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm number of tweets indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzz...zzz...\n",
      "Found 12908 indexed tweets\n"
     ]
    }
   ],
   "source": [
    "# There seems to be latency between indexing and getting\n",
    "# correct search results. Introduce a short wait...\n",
    "sleep_time = 0.50\n",
    "search = Search(using=es, index='twitter', doc_type='tweet')\n",
    "while True:\n",
    "    if search.count() == all_indexed:\n",
    "        break\n",
    "    print('zzz...', end='')\n",
    "    time.sleep(sleep_time)\n",
    "print(f'\\nFound {all_indexed} indexed tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
