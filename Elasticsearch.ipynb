{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For guidance, see [Elastic Stack and Product Documentation](https://www.elastic.co/guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Elasticsearch Client docs at http://elasticsearch-py.readthedocs.io\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pathlib\n",
    "import time\n",
    "# twittertools is my local twittertools.py module\n",
    "import twittertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Elasticsearch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default connection to localhost:9200\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print current indices for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow open twitter HxCSFDvTT7W_4tFOnkr-IQ 5 1 12820 0  8.7mb  8.7mb\n",
      "yellow open .kibana Yuy-vovlQyeUPVim2PcdFw 1 1     2 0 10.9kb 10.9kb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(es.cat.indices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweets from a few Twitter user timelines; index them in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration only, delete any existing /twitter index\n",
    "result = es.indices.delete(index='twitter', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Authenticated TwitterTools object\n",
    "filepath = pathlib.Path.home().joinpath('.twitter', 'credentials.json')\n",
    "twt = twittertools.TwitterTools(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203 tweets retrieved from @pourmecoffee's timeline; 3203 indexed\n",
      "3206 tweets retrieved from @washingtonpost's timeline; 3206 indexed\n",
      "3217 tweets retrieved from @brainpicker's timeline; 3217 indexed\n",
      "3194 tweets retrieved from @wilw's timeline; 3194 indexed\n",
      "Total tweets indexed: 12820\n"
     ]
    }
   ],
   "source": [
    "all_indexed = 0\n",
    "total_tweets = 0\n",
    "screen_names = ['pourmecoffee', 'washingtonpost', 'brainpicker', 'wilw']\n",
    "for screen_name in screen_names: \n",
    "    tweets = twt.get_user_timeline(screen_name)\n",
    "    total_tweets += len(tweets)\n",
    "    print(f\"{len(tweets)} tweets retrieved from @{screen_name}'s timeline;\", end=' ')\n",
    "    total_indexed = 0\n",
    "    for tweet in tweets:\n",
    "        doc = twittertools.unpack_tweet(tweet)\n",
    "        result = es.index(index='twitter', doc_type='tweet', body=doc)\n",
    "        if result['_shards']['successful']:\n",
    "            total_indexed += 1\n",
    "    print(f'{total_indexed} indexed', flush=True)\n",
    "    all_indexed += total_indexed\n",
    "print('Total tweets indexed:', all_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm number of tweets indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 12820 indexed tweets\n"
     ]
    }
   ],
   "source": [
    "# There may be latency between indexing and getting\n",
    "# complete search results. Introduce a short wait...\n",
    "max_wait = 5.0  # seconds\n",
    "sleep_wait = 0.50\n",
    "sleep_count = 0\n",
    "search = Search(using=es, index='twitter', doc_type='tweet')\n",
    "while True:\n",
    "    doc_count = search.count()\n",
    "    if doc_count == all_indexed:\n",
    "        break\n",
    "    sleep_count += 1\n",
    "    if sleep_count*sleep_wait > max_wait:\n",
    "        break\n",
    "    time.sleep(sleep_wait)\n",
    "print(f'\\nFound {doc_count} indexed tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform simple match query on tweet texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 36 matches\n",
      "Top ten by relevance score:\n",
      "- pourmecoffee 2017-06-05T22:31:52Z @NASA Like my tweets.\n",
      "- pourmecoffee 2017-06-29T17:40:25Z @NASA @CassiniSaturn pierogi mmm\n",
      "- pourmecoffee 2017-07-12T18:24:04Z @NASA Finally some non-Manhatten-sized icebergs.\n",
      "- pourmecoffee 2017-09-10T01:43:52Z NASA engineers these releases every ten years to keep the people docile. I've said too much already.\n",
      "- pourmecoffee 2017-08-18T11:51:27Z @NASA @NASA_TDRS You're firing on Earth do you take me for a fool?\n",
      "- washingtonpost 2017-11-29T08:05:43Z A NASA astronaut films his spacewalk — and a breathtaking view of Earth https://t.co/ZaCEVRbTME\n",
      "- washingtonpost 2017-11-15T16:12:53Z These close-up images from NASA show one of the largest icebergs to ever split off from Antarctica https://t.co/Rxa7ScbGII\n",
      "- pourmecoffee 2017-07-23T01:22:29Z This is it. Just rely on your training and your unit now. \"NASA Watches a Sunspot Turn Toward Earth\"… https://t.co/RsNmQrLo35\n",
      "- washingtonpost 2017-11-19T15:04:44Z Perspective: Please stop annoying this NASA scientist with your ridiculous Planet X doomsday theories https://t.co/soTGVzQqqm\n",
      "- washingtonpost 2017-11-16T05:47:56Z These are the melting glaciers that might someday drown your city, according to NASA https://t.co/f2fd7fUexU\n"
     ]
    }
   ],
   "source": [
    "results = search.query(\"match\", text=\"NASA\").execute()\n",
    "print(f'Got {results[\"hits\"][\"total\"]} matches')\n",
    "print('Top ten by relevance score:')\n",
    "for hit in results['hits']['hits']:\n",
    "    tweet = hit['_source']\n",
    "    print('-', tweet['screen_name'], tweet['created'], tweet['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
